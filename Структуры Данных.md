#  Организационные вопросы:
Курс структура разделен также, как и в первом семестре на 2 раздела:
- Структуры данных;
- Дополнительные главы программирования (продолжение);

*Форма аттестации по курсам*:
- Структуры данных: Экзамен и курсовая работа;
- Дополнительные главы программирования (продолжение): Экзамен;

Будет использоваться бальная система, такая же, как и в первом семестре. Штрафные баллы будут начисляться строже, ошибки первого семестра недопустимы.

*Курсовая работа отличается от задания*:
- По курсовой работе отдельная ведомость (отдельная форма аттестации);
- Курсовая работа отличается объемом (месяц на выполнение);
- Исследовательский характер работы (требуется провести эксперименты);
- По курсовой работе необходим отчет, который готовиться по шаблону. Если курсовая написана хорошо, а отчет по курсовой плохой, то такая работа не может быть зачтена;

*Отчет* - это обучение студента писать техническую документацию, так как любой специалист IT должен уметь писать и читать техническую документацию.
Смысл отчета в том, если какой-то сторонний человек захочет узнать, что и как было сделано, то он должен взять, прочитать и понять, как и что было сделано.
Отчет должен быть самодостаточным и должен работать без комментариев.

## Общая информация о курсовой работе
Смысл курсовой работы: Компьютерная игра, которую необходимо запрограммировать. Это игра в подкидного дурака в карты 1 на 1. 
Необходимо запрограммировать бота, который играет в карты, ходить (атаковать) в свой ход или защищаться (отбиваться), подкидывать из прикупа, оценивать шансы и т.д.
После того, как студенты запрограммировали ботов, боты играют между собой.
Есть центральный модуль, который управляет игрой и компилирует необходимые файлы.
Функция атаки/защиты, должны иметь одинаковые аргументы, для того, чтобы центральный модуль мог запрашивать эти функции.

Не получится защитить курсовую работу, если написан просто бот, программа должна стараться выиграть противника. Необходимо придумать стратегию и обосновать, а потом запрограммировать и протестировать ее.

Протестировать можно с примитивным ботом, которого необходимо обыгрывать более, чем с 50% уровнем.
Есть программная среда, которая может протестировать написанного бота.
Все будет открыто на дистанционном курсе.

В части курсовой работы можно использовать немного больше, чем изучаем на курсе, к примеру, структуры данных, которые не изучали.


# Лекция 1: Оценка эффективности алгоритмов

## Структуры данных
* Переменные простых (стандартных) типов - используются для хранения небольшого количества информации.
Переменная простого (стандартного) типа данных характерна тем, что память выделяемая для такой переменной - фиксирована. Пример, для переменной типа: "int" выделяется 4 байта, для переменной типа: "double" выделяется 8 байт и т.д. но есть и исключения, к примеру, переменная типа: "string" для которой память выделяется от количества символов.
Использование переменных простых (стандартных) типов не всегда может устроить:
- если, к примеру, данных много несколько сотен или тысяч;
- неизвестно заранее количество данных с которым необходимо работать. К примеру, открываем файл и необходимо работать с данными, которые находятся в файле;
- если все же объявили 100 переменных для чисел с типом: "int", то с такими данными неудобно работать. К примеру, может потребовать сложить или вычесть данные числа;
- иногда, кроме самих данных, необходимо хранить информацию об их взаимосвязи. К примеру, папки и файлы на диске организованны в виде иерархии, нам необходимо знать какая папка находится внутри другой и какая у них взаимосвязь.

Все указанные причины не позволяют использовать простые типы данных и поэтому используют сложные (составные) типы данных, они как раз и называются структуры данных.

Одно из основных отличий составного (сложного) типа данных от простого типа данных заключается в том, что в составном типе данных информация хранится не атомарная не что-то одно, а хранится множество данных. К примеру, в массиве хранятся ячейки и в каждой ячейке хранится своя информация.

Составные (сложные) типы данных позволяют:
- эффективно организовывать доступ к информации, которая находится внутри. К примеру, с помощью цикла можно обойти все ячейки массива;
- динамически управлять данными. К примеру, увеличить количество ячеек массива, добавить элемент массива и т.д.;

Кроме массивов также есть стеки (которых множество), списки хэш-таблицы, деревья (которых множество), 

Для большего количества данных и для представления связей между данными нужно использовать структуры данных.
- Знать основные способы организации данных: массивы, списки, стеки, очереди и т.п. и уметь выбирать оптимальный вариант;
- Знать алгоритмы для структур данных и уметь выбирать оптимальный вариант;

Структуры данных, которые будут изучаться на курсе, есть 2 возможных варианта:
- либо использовать готовые классы;
- либо запрограммировать все самим;

С массивами все однозначно, нужно использовать готовый класс.
Дерево необходимо запрограммировать самим, так как готовый класс в C# - отсутствует.
Список или очередь, есть нюансы, так как есть готовый класс: "List" (список) или "Queue" (очередь), а можно запрограммировать самим.

**!!!Важный момент!!!**
Не всякое решение задачи может считаться хорошим. Почти любую задачу можно решить разными способами. Возникает следующий вопрос, а какой из способов лучше. Возникают 2 момента:
1. Как измерять оптимальность алгоритма?
2. Как придумать алгоритм и оценить его оптимальность?
Оба эти момента опираются на разделы математики.

## Оценка эффективности алгоритмов
- Увеличение эффективности алгоритмов существенно сказывается на результате по сравнению например с аппаратными изменениями
- Любую задачу можно решить разными способами (алгоритмами, методами). А значит актуальным является вопрос сравнения (анализа)

*Способы увеличения эффективности алгоритмов*:
- Алгоритмический подход. Придумаем кардинально другой алгоритм. Пример: сортировка массива, можно сортировать пузырьком, можно сортировать быстрой сортировкой, можно поиск элемента делать линейно, а можно использовать бинарный поиск.
- Технический подход. Использование таких операторов или команд, которые на конкретной платформе работают быстрее. Пример: определение числа на четность, можно пытаться найти остаток от деления и сравнивать с нулем, а можно посмотреть младший бит у числа операцией маскирования и если он равен "0", то число четное, а если он равен "1", то число нечетное. Есть также приемы свойственные конкретным аппаратным средствам, т.е. на этом типе процессоров на этом оборудовании эта команда будет работать быстрее, а на другой платформе может и нет.

Разница алгоритмической оптимизации и технической в том, что алгоритмическую оптимизацию можно провести на бумаге без компьютера, описать алгоритм и сравнить один алгоритм с другим и это правильно. Оценка на листе бумаги экономит много времени, денег и сил, так как позволяет не писать много лишнего кода и помогает до написания кода выбрать лучший алгоритм, а для этого нужно уметь алгоритмически и математически мыслить.
Техническая оптимизация невозможна на листе бумаги, так как это конкретный язык программирования, конкретный компилятор и конкретная среда и т.д.

## Критерии сравнения алгоритмов

***Два основных показателя сравнения эффективности алгоритмов***: 
- Временной показатель;
- Показатель по памяти (ёмкостной);

***Другие критерии (часто не количественные)***:
- Масштабируемость и модифицируемость
- Размер (мощность) множества входных данных
- Легкость отладки (чтения)
- Другое


**Показатель по памяти (ёмкостной)**. Зависимость требуемой для работы программы памяти от размера (или других показателей) входных данных. Если объем выделяемой памяти = const, то это не представляет интереса (кроме тонкой настройки). 

Речь не о входных данных, а о дополнительной памяти, которая программа объявляет. Если объем вспомогательной (выделяемой) памяти = const и от объема входных данных не зависит, то этот показатель не так интересен, возможны улучшения, но чисто косметические. Представляет интерес, когда этот показатель зависит от объема входных данных, например, чем больше входных данных, тем больше дополнительной памяти требуется алгоритму.
К примеру, пишем функцию фильтрации элементов в массиве, которая создает новый массив и включает в него только положительные значения и они должны быть отсортированы. 
Можно на старте объявить дублирующий массив, такого же размера, как входной и переписать в него в цикле числа больше нуля, а потом его отсортировать и вернуть, как результат. Альтернатива, можно попытаться все действия сделать с оригинальным массивом, к примеру, отсортировать массив и отрезать отрицательную часть.
Если ячеек во входящем массиве 1 млн., то если объявить дублирующий массив, памяти может и не хватить. 

**Временной показатель**. Чем меньше алгоритму необходимо времени для достижения цели, тем лучше;
 * Оценка качества работы алгоритма по времени: в секундах? (плохо, так как ПК может быть загружен другими операциями, оценка должна идти на листочке) Проблема: разная среда выполнения, необходима оценка до практической реализации;
 * Решение - оценка количества действий.
	* = (равно) константа, тогда тонкая;
	* != (не равно) константа, если алгоритм итерационный или рекурсивный;
* Количество итераций (операций) зависит от входных данных (размера и информации). Нам интересно не само значение, а зависимость (функция, описывающая зависимость) количества итераций от входных данных.
 
 В теории алгоритмов оценка делается в количестве операций (в количестве итераций - более правильно говорить).
 Нет задачи посчитать, сколько действий точно было выполнено. Итерации возникают только если есть циклы или рекурсия. 
 Если циклов или рекурсии нет, то алгоритм линейный, а значит оценка его временной эффективности не интересна. Какие бы данные не были поданы на вход алгоритму, время будет одинаково. К примеру, алгоритм определяет какой число, положительное или отрицательное, находится в первой ячейке массива. Время выполнения алгоритма (количество итераций) не зависит от размера массива и нет интереса что-то сравнивать, возможна только тонкая настройка на уровне операторов.
 Когда алгоритм нелинейный, т.е. есть циклы или рекурсия, то тогда это представляет интерес, так как чаще всего количество итераций в циклах или количество рекурсивных вызовов, зависит от объема входных данных. Нам интересно не само число итераций, а зависимость.
 
 **Временная оценка делается путем сравнения скорости роста функции, которая описывает зависимость: объем входных данных и количества операций.**

Если мы входной объем данных увеличили в 10 раз и количество итераций увеличилось в 10 раз, то это линейная зависимость.
Квадратичная зависимость, это когда входной объем данных увеличили в 10 раз и количество итераций увеличилось в 100 раз.
Логарифмическая функция растет медленнее, чем линейная функция.

## Оценка вычислительной сложности

* Входные данные: худший случай (O), лучший случай (o), средний
* Операции с нотацией O
	* Вложенный вызов: O(F1) * O(F2)
	* Последовательный вызов: O(F1) + O(F2) = O(F1) (если F1 быстрее растет)
* Асимптотическая сложность. Классы алгоритмов P (полиноминально зависит) и NP;
* Оценка времени выполнения алгоритма на:

|     | N=10    | N=20            | N=30             | N=40             | N=50             |
| --- | ------- | --------------- | ---------------- | ---------------- | ---------------- |
| N^3 | 0.001 с | 0.008 с         | 0.027 с          | 0.064 с          | 0.125 с          |
| 2^N | 0.001 с | 1.05 с          | 17.9 м           | 1.29 дней        | 35.7 лет         |
| 3^N | 0.059 с | 58.1 м          | 6.53 лет         | 3.86 * 10^5 лет  | 2.28 * 10^10 лет |
| N!  | 3.63 с  | 7.71 * 10^4 лет | 8.41 * 10^18 лет | 2.59 * 10^34 лет | 9.64 * 10^50 лет |

Задачи, которые описываются в алгоритмизации, принято делить на 2 категории:
- NP (не полиноминальные алгоритмы). В данных алгоритмах, скорость роста функции существенно больше, чем у полинома. Такого рода задачи, требуют нестандартного подхода;
- P (полиноминальные алгоритмы). С данными алгоритмами все хорошо, можно взять "технику" помощнее и будет быстрее работать;

С точки зрения теории алгоритмизации, главной задачей оптимизации является улучшение именно функции.

Но есть более тонкая оптимизация, когда саму функцию не улучшаем, а улучшаем конкретные действия, в таком случае, число итераций остается таким же, но сами итерации оптимизируются.

*Пример*: Есть массив студентов, в котором необходимо найти определенного студента по идентификационному номеру. Массив не отсортирован.
- В лучшем случае, N (количество итераций) = 1;
- В худшем случае,  N (количество итераций) = длине массива;
- Среднее значение, это N/2;

Среднее значение найти не так просто, так как необходимо обладать информацией о входных данных и понимать, есть ли в них точно искомый элемент или его нет и какова доля вероятности, что искомый элемент точно есть в массиве, поэтому распределение точно будет больше, чем N/2.

***С точки зрения теории алгоритмизации, оценка алгоритма должна быть универсальной и независима от входных данных.***

Лучший случай всегда будет N = 1, а худший O(N), а для определения  среднего значения, необходимы дополнительные сведения. Поэтому, на практике средняя оценка используется редко, чаще всего используется оценка худшего случая, иногда используется оценка лучшего случая.

Для описания оценки вычислительной сложности алгоритмов используется нотация (форма записи): O (функция) - это оценка алгоритма с точки зрения худшего случая, т.е. оценка зависимости числа итераций от объема входных данных, тем самым мы можем сказать, что алгоритм будет работать O(F) или быстрее.

Оценка худшего случая - это оценка сверху.

При рассмотрении алгоритмов зачастую не так легко дать оценку худшего случая, но на простом уровне можно запомнить базовые моменты:
- Если части алгоритма вложенные, то необходимо использовать операцию умножения для итоговой оценки вычислительной сложности: O(F1) * O(F2);
- Если блоки идут последовательно, то необходимо использовать операцию сложения для итоговой оценки вычислительной сложности: O(F1) + O(F2) = O(F1) (если F1 быстрее растет);

С точки зрения теории алгоритмизации, из суммы берут слагаемое (функцию), которая быстрее растет. К примеру, O(N^2) +  = O(N^2), а функцию O(N) можно не учитывать и говорить, о том, что наш алгоритм имеет квадратичную сложность:  O(N^2). По этой же причине, можно не учитывать и константы.

На занятиях мы не будем заниматься оценкой вычислительной сложности, а будем по большей части брать оценки из литературы.




